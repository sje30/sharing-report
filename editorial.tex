\documentclass[11pt]{article}

\usepackage[colorlinks=true,linkcolor=black,citecolor=black,urlcolor=black]{hyperref}
\usepackage{amsmath,mathpazo,graphicx,doi}

\usepackage[a4paper,margin=3cm]{geometry}

\usepackage{xspace}
\usepackage{setspace}


\RequirePackage{lineno} 
\modulolinenumbers[2]

\usepackage[style=nature,articletitle=true,isbn=false,backend=bibtex]{biblatex}
\bibliography{editorial}
\AtEveryBibitem{\clearfield{month}}

\begin{document}

\doublespacing

\title{Towards standard practices for sharing computer code and programs in Neuroscience}

\author{Stephen J. Eglen$^{1,\dagger}$, Ben Marwick${^2}$, Yaroslav O. Halchenko${^3}$, your names here, Jean-Baptiste Poline${^4}$}
\date{\today}
\maketitle

\noindent $^{1}$ 
Cambridge Computational Biology Institute\\
Department of Applied Mathematics and Theoretical Physics\\
University of Cambridge\\
Wilberforce Road, Cambridge CB3 0WA, UK
\vspace*{2mm}

\noindent $^{2}$ 
Department of Anthropology\\
University of Washington\\
Seattle, WA 98195-3100 USA 
\vspace*{2mm}

\noindent $^{3}$
Department of Psychological and Brain Sciences\\
Dartmouth College\\
Hanover, NH 03755 USA
\vspace*{2mm}

\noindent $^4$ JB address

\vspace*{2mm}


\noindent $\dagger$
Corresponding author.\\
\noindent Phone: +44 (0) 1223 765761
\noindent Email: S.J.Eglen@damtp.cam.ac.uk



\vspace*{2cm}
\subsection*{Abbreviations}
\begin{tabular}{ll}
\end{tabular}


\clearpage


\renewcommand{\cite}[1]{\autocite{#1}}

\linenumbers

\section*{Background}

Many areas of neuroscience are now critically dependent on
computational tools to help understand the large volumes of data being
created.  Furthermore, computer models are increasingly being used to
help predict and understand the function of the nervous system.  Many
of these computations are complex, and often cannot be concisely
reported in the methods section of a scientific article.  In a few
areas there is a short list of the software packages mostly used for
analysis (e.g., SPM, FSL, AFNI, FreeSurfer in neuroimaging).  However,
we often write new computer programs to solve specific problems in the
course of our research.  Some of these programs may be relatively
small scripts that help analyze all of our data, and these rarely get
described in papers.  As authors, how best can we maximize the chances
that other scientists can reproduce our computations or reuse our
methods on their data?  Is our research reproducible?

To date, the sharing of computer programs underlying neuroscience
research has been the exception (see below for some examples), rather than the rule.  However, there
are many benefits to sharing these programs, including increased
understanding and reuse of your work.  Furthermore, open source programs can be scrutinized and improved, whereas the functioning of closed source
programs remain forever unclear \cite{Vihinen2015}.  Funding agencies, research institutes and publishers are all gradually developing policies to
reduce the withholding of computer programs relating to research
\cite{Morin2012-65e}.  The Nature family of journals have recently
published opinion pieces in favor of sharing whatever code is
available, in whatever form \cite{Barnes2010-iv,Ince2012-225}.  More
recently, since October 2014, all Nature journals require papers to
include a statement declaring \textit{if} the programs underlying central
results in a paper are available. In April 2015 \textit{Nature Biotechnology} offered recommendations for providing code with papers and began asking referees to give feedback on their ability to test code that accompanies submitted manuscripts \cite{NatBiotech2015}.
In July 2015 F1000Research stated that ``Software papers describing non-open software, code and/or web tools will be rejected'' (\url{http://f1000research.com/channels/f1000-faculty-reviews/for-authors/article-guidelines/software-tool-articles}).

\subsection*{Current position}

To help the editors of \textit{Nature Neuroscience} and
\textit{Scientific Data} to evaluate if appropriate code is being
shared, we are now helping to run a one-year trial by adding a small
extra step to the manuscript review process.  During review, a
computational expert will be asked to check what code has been
provided, and to write a brief report commenting on its quality
according to criteria outlined below (``Simple steps to help you share
your code'').  There is no expectation that the expert will re-run the
programs, as often this can take days to recreate the computational
environment, and computations could take many months to complete.
Furthermore, this report will not prevent publication of a manuscript, as the current policy at Nature is not mandatory.


\subsection*{What should be shared?}

It may not be obvious what to share, especially for complex projects with many collaborators.  Ideally,
you should share as much code and data to allow others to reproduce
your work,  but this may not be possible/practical.  However, it
is expected that you will share key parts of the work, e.g. implementations of novel algorithms or analysis.  By getting into the habit of sharing as much as possible, not only do you help others who wish to reproduce your work, you will be helping other members of your laboratory, or even yourself in the future.  By sharing your code publicly, you are more likely to write higher-quality code \cite{Easterbrook2014}, and you will know where to find it after you've moved on from the project, rather than the code disappearing on a colleague's laptop when they leave your group. In addition, as advocated by Claerbout and Donoho, for computational sciences the scholarship is not the article, the "scholarship is the complete software [...]" \cite{claerbout_electronic_1992,donoho_invitation_2010}.
% TODO: possibly inject idea from {Halchenko2015} that sharing your code openly guarantees availability of it to yourself later on happen you change employer

\subsection*{Simple steps to help you share your code}

Once you have decided \textit{what} you plan to share, here are some simple 
guidelines for \textit{how} to share your work.  Note that in many cases these
principles should be followed throughout the lifetime of your project,
not just at the end when you wish to publish your results. Guidelines similar to these have been proposed recently in many areas of science \cite{Nosek2015, miguel2014, stodden2012journals}, suggesting that they are part of norms that are emerging across disciplines. In the `further reading' section below we list some specific proposals from other fields that expand on the guidelines we suggest here.  

\begin{description}
\item [Version control] Use a version control system (such as Git) to
  develop the code.  The version control database can then be easily
  and freely shared with others using sites such as
  \url{http://github.com} \cite{Ram2013} or
  \url{https://bitbucket.org}.  These sites allow you fine control
  over private versus public access to your code.  This means that you
  can keep your code repository private during its development, and
  then publicly share the repository at a later stage e.g. at the time
  of publication.
  
  \textit{One wrinkle: this private vs public repo setup does not
    solve the problem of how to share your private repo with anonymous
    reviewers pre publication -- do we want to recommend a solution --
    just submit a .zip file? Another solution is to create a new user
    on github, e.g. ``sharingreport-editor'', with access to the
    project, and send the password and username to the editor during
    the review process.  My solution so far has been to make the repo
    public when paper is submitted for review.}

\item [Persistent URLs] Generate stable URLs (such as a DOI) for key
  versions of your software.  This can be done freely and routinely with sites
  such as \url{http://zenodo.org}.  If your work includes computer
  models of neural systems, you may wish to consider depositing these
  models in established repositories such as ModelDB
  (\url{https://senselab.med.yale.edu/}) or
  \url{http://opensourcebrain.org} or NITRC \cite{poline_software_2014}.
% TODO: there is also https://www.force11.org/group/resource-identification-initiative now which is piloted/supported by a few publishers

\item [License] Choose a suitable license for your code to assert how
  you wish others to reuse your code  For example, to maximise reuse,
  you may wish to use a permissive license such as MIT or BSD
  \cite{Stodden2009}.  Licenses are also important to protect you from
  others misusing your code.  Visit \url{http://choosealicense.com/}
  to get a simple overview of which license to choose, or 
  \url{http://www.software.ac.uk/resources/guides/adopting-open-source-licence}
  for a detailed guide.

\item [Etiquette] When working with code written by others, observe Daniel Kahneman's  'reproducibility etiquette'\cite{Kahneman2014} and have a discussion with the authors of the code to give them a chance to fix bugs or respond to issues you have identified before you make any public statements. 

\item [Documentation] Contrary to popular expectations, you do not
  need to write extensive documentation or a user's guide for the code
  still be to useful to others \cite{Barnes2010-iv}.  However, it is
  worth providing a minimal README file to give an introduction to
  what the code does, and how to run it.  For example, you should provide
  instructions on how to regenerate a key result, or a particular
  figure from a paper. Literate programming methods, where code and narrative text are interwoven in the same document, make documentation semi-automatic and can save a lot of time when preparing code to accompany a publication \cite{schulte2012multi, gentleman2012statistical}. In any cases, well documented code allows for easier re-use and checking.

\item [Tools and case studies] Consider using modern, widely used software tools that can help with making your computational research reproducible.  Many of
  these tools have already been used in Neuroscience and serve as good
  examples to follow, for example Org mode \cite{Delescluse2011},
  IPython/Jupyter \cite{Stevens2013} and Knitr \cite{Eglen2014}.  Other
  prominent examples of reproducible research in Computational
  Neuroscience include Vogels et al. \cite{Vogels2011-c8c} and Waskom et al. \cite{Waskom2014-gd}.
  Virtualization environments, such as VirtualBox appliances and
  Docker containers, can also be used to
  encapsulate or preserve all of the computational environment so that
  other users can run your code with having to install numerous dependencies \cite{Boettiger2015}.

\item [Include some tests] Testing the code has long been recognized
  as a critical step in software industry but the practice is not
  widely adopted yet by researchers. We recommend including tests that
  demonstrate the code is producing the correct
  results\cite{Axelrod2014-xi}. These tests can be at a low level
  (testing each individual function, called unit testing) or at a
  higher level (e.g. testing that the program yields correct answers
  on simulated data) \cite{wilson_best_2014}.

\end{description}

\subsection*{Further reading}

Varsha Khodiyar 2015 Code Sharing – read our tips and share your own. Scientific Data Blog, February 19, 2015. \url{http://blogs.nature.com/scientificdata/2015/02/19/code-sharing-tips/}

Leveque, Randall 2012. Top Ten Reasons to Not Share Your Code (and why you should anyway). 
\url{http://faculty.washington.edu/rjl/pubs/topten/topten.pdf}

Stodden, V. \& Miguez, S., 2014. Best Practices for Computational Science: Software Infrastructure and Environments for Reproducible and Extensible Research. Journal of Open Research Software. 2(1), p.e21. DOI: \url{http://doi.org/10.5334/jors.ay}

Stodden, V., Leisch, F., \& Peng R. (Eds.). (2014). Implementing Reproducible Research. CRC press, Chapman and Hall. \cite{victoria_stodden_implementing_2014}

Halchenko, Y. O. and Hanke, M. (2015). Four aspects to make science open ``by design'' and not as an after-thought. GigaScience, 4. DOI: 10.1186/s13742-015-0072-7 \cite{Halchenko2015}

Several online forums are available for discussing issues related to
this article.  One popular forum is
\url{http://academia.stackexchange.com/questions/tagged/reproducible-research}.

% maybe mention the new Stackexchange site that is going into Beta
% July 2015, "Open Science".



\subsection*{Closing remarks}

Changing the behaviors of Neuroscientists so that they make their code more available 
will likely be resisted by those who do not see the community benefits as outweighing 
the personal costs of the time and effort required to share code \cite{stodden2010scientific}. 
The community benefits, in our view, are obvious and substantial: we can demonstrate 
more robustly and transparently the reliability of our results, we can more easily adapt
 methods developed by others to our data, and the impact of our work increases as others 
 can similarly reuse our methods on their data. Thus, we will endeavor to lead 
 by example, and follow all these practices as part of our future work in all scientific publications. 
 Even if the code we produce today will not run ten years from now, it will still be a more precise 
 and efficient expression of our analysis than the text of the methods section in our paper. 

However, exhortations such as this editorial are only a small part of making 
code sharing a normal part of doing Neuroscience. Other efforts might include: training  
students,  postdocs and researchers in sound coding principles so that they are not anxious to share their code, 
publishing research that includes code in an open repository, requesting code and data when reviewing, 
submitting to and reviewing for journals that support code sharing, critically reviewing  grant proposals
 for mentions of code availability, and recognizing efforts toward openness in hiring, promotion, 
 and reference letters \cite{leveque2012reproducible}. This combination of efforts on a variety of fronts 
 will increase the visibility of research accompanied by open source code, and demonstrate to 
 others in the discipline that code sharing is a desirable activity that helps move the field forward. 

We believe that the sociological aspects of code sharing may be harder to overcome than the technical ones.
Currently, academic success is strongly linked to publications but hardly to the code produced. Code may also be seen as providing a competitive advantage to researchers rather than be a part of the products which should be by default shared by largely publicly funded research. We are therefore advocating for a more global culture change embracing transparency, reproducibility and re-usability of research products.   

\subsection*{Acknowledgments}

This article is based upon discussions from a workshop to encourage
sharing in neuroscience, held in Cambridge, December 2014.  It was
financially supported and organized by the International
Neuroinformatics Coordinating Facility (\url{http://www.incf.org}),
with additional support from the Software Sustainability institute
(\url{http://www.software.ac.uk}).


\printbibliography



\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-PDF-mode: t
%%% TeX-master: t
%%% ispell-local-dictionary: "american"
%%% auto-fill-inhibit-regexp: ".*[&|].*[&|].*"
%%% End:
